{
  "description": "\"Towards Causal Foundations of Safe AI\"\nJames Fox, Tom Everitt\n\nWith great power comes great responsibility. Artificial intelligence (AI) is rapidly gaining new capabilities, and is increasingly trusted to make decisions impacting humans in significant ways (from self-driving cars to stock-trading to hiring decisions). To ensure that AI behaves in ethical and robustly beneficial ways, we must identify potential pitfalls and develop effective mitigation strategies. In this tutorial, we will explain how (Pearlian) causality offers a useful formal framework for reasoning about AI risk and describe recent work on this topic. In particular, we\u2019ll cover: causal models of agents and how to discover them; causal definitions of fairness, intent, harm, and incentives; and risks from AI such as misgeneralization and preference manipulation, as well as how mitigation techniques including impact measures, interpretability, and path-specific objectives can help address them.",
  "duration": 5769,
  "language": "eng",
  "recorded": "2023-07-31",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://www.auai.org/uai2023/"
    }
  ],
  "speakers": [
    "James Fox",
    "Tom Everitt"
  ],
  "tags": [
    "tutorial"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/SvK-bV5NWhg/maxresdefault.jpg",
  "title": "Towards Causal Foundations of Safe AI",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=SvK-bV5NWhg"
    }
  ]
}
