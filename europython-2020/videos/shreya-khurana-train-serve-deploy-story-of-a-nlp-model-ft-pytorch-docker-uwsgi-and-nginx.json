{
  "copyright_text": "This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/\nPlease see our speaker release agreement for details: https://ep2020.europython.eu/events/speaker-release-agreement/\n",
  "description": "\"Train. Serve. Deploy! Story of a NLP Model ft. PyTorch, Docker, Uwsgi and Nginx\nEuroPython 2020 - Talk - 2020-07-23 - Parrot Data Science\nOnline\n\nBy Shreya Khurana\n\nNatural language processing has seen leaps of technology progress with Machine Learning becoming the norm of solving the major problems in this area, with Machine translation being one of the major problems in this area. Neural machine translation systems are now used to convert sentences or phrases from one language to another, or in general, for sequence to sequence modeling. In this talk, we\u2019ll be covering the steps from scratch to preprocess, train and serve a NMT model using PyTorch. While building a highly accurate model is a prerequisite to getting good quality translations, often in industry, we also need to make sure we can serve the model to customers without getting timeouts or delays. The practice of serving models requires creating a web app to get client requests and process them in a way the model would understand. For this, we\u2019ll use  the various components of the application server environment - Flask, Docker, uwsgi and nginx. This talk is suitable for audience who is working in general with ML models and want to learn how to serve them or working specifically with NMT and want to learn about some quick prototyping tips. \n\nPrerequisites: Audience should be comfortable with the basic ML terminology and procedure of training models. NLP knowledge will be good, but is not a necessity as the focus will be on quick prototyping in production.\n\nBy the end of the talk, the audience will have:\n- Learnt how to preprocess data for NLP systems\n- Learnt how to quickly prototype and train a translation model\n- Learnt how to create a web app for the NLP model using Flask\n- Learnt how to containerize a pytorch model using Docker\n- Learnt how to serve the model as an app using uwsgi, nginx and \n\nOutline:\n\n\nIntroduction to translation systems, machine translation framework\n\n\nML Modelling \n- Preprocessing data\n- Training \n- Generating new translations \n\nServing and prototyping \n- Flask app \n- Docker container br /\n- Nginx + uwsgi + supervisord configurations \n- Putting it all together \n\nGood practices \nQ/A (optional?)\n\n\n\nLicense: This video is licensed under the CC BY-NC-SA 3.0 license: https://creativecommons.org/licenses/by-nc-sa/3.0/\nPlease see our speaker release agreement for details: https://ep2020.europython.eu/events/speaker-release-agreement/\n\n\"",
  "duration": 1782,
  "language": "eng",
  "recorded": "2020-07-23",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://ep2020.europython.eu/"
    },
    {
      "label": "https://ep2020.europython.eu/events/speaker-release-agreement/",
      "url": "https://ep2020.europython.eu/events/speaker-release-agreement/"
    },
    {
      "label": "https://creativecommons.org/licenses/by-nc-sa/3.0/",
      "url": "https://creativecommons.org/licenses/by-nc-sa/3.0/"
    }
  ],
  "speakers": [
    "Shreya Khurana"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/BSDW8PWUVF0/sddefault.jpg",
  "title": "Train. Serve. Deploy! Story of a NLP Model ft. PyTorch, Docker, Uwsgi and Nginx",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=BSDW8PWUVF0"
    }
  ]
}
