{
  "description": "Recent progress in generating natural language text catches media\nattention. Are we about to get flooded by autogenerated fake news? Let's\nlearn about approaches to machine-generated text. Get a high level idea\nof how can you apply basic approaches like N-grams, HMMs as well as\nadvanced ones such as RNNs and VAEs. We'll apply those methods to\nreal-world datasets of Polish articles from Wikipedia.\n\nRecent progress in generating natural language text sparks controversy\nand catches global media attention. Are we about to get flooded by\nmachine- generated fake news? Are we on the edge of a completely new\nlevel of troll farms about to emerge? In this talk I will go over\napproaches to machine- generated text. You will get a high level idea of\nhow can you apply basic approaches like N-grams, Hidden Markov Model as\nwell as advanced ones such as RNNs and Variational Autoencoders. We will\ncover the main challenges like methods of evaluation, and potential use\ncases. We will also have fun applying aforementioned methods into real\nworld datasets of Polish articles from Wikipedia.\n",
  "duration": 1499,
  "published_at": "2020-01-03T00:31:43.000Z",
  "recorded": "2019-12-12",
  "speakers": [
    "Tomasz Dziopa"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/Pj4TPWy-_4I/hqdefault.jpg",
  "title": "Generative Text Modelling: Scratching the surface",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=Pj4TPWy-_4I"
    }
  ]
}
