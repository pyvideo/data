{
  "description": "Transfer learning has been changing the NLP landscape tremendously since\nthe release of BERT one year ago. Transformers of all kinds have\nemerged, dominate most research leaderboards and have made their way\ninto industrial applications. In this talk we will dissect the paradigm\nof transfer learning and its effects on pipelines, modelling and the\nengineers mindset.\n\nSufficient training data is often a bottleneck for real-world machine\nlearning applications. The computer vision community mitigated this\nproblem by pretraining models on ImageNet and transferring knowledge to\nthe desired task. Thanks to an emerging new class of deep language\nmodels, transfer learning has also become the new standard in NLP. In\nthis talk we will share strategies, tips & tricks along all model\nphases: Pretraining a language model from scratch, adjusting it for\ndomain specific language and fine-tuning it for the desired down-stream\ntask. We will demonstrate the practical implications by showing how\nmodels like BERT caused major breakthroughs for the task of Question\nAnswering.\n",
  "duration": 2729,
  "published_at": "2020-01-03T02:09:49.000Z",
  "recorded": "2019-12-13",
  "speakers": [
    "Malte Pietsch"
  ],
  "tags": [
    "keynote"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/0lvjpMHp4vQ/hqdefault.jpg",
  "title": "Keynote: Transfer Learning - Entering a new era in NLP",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=0lvjpMHp4vQ"
    }
  ]
}
