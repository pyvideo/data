{
  "description": "When Bayesian modeling scales up to large datasets, traditional MCMC methods can become impractical due to their computational demands. Variational Inference (VI) offers a scalable alternative, trading exactness for speed while retaining the essence of Bayesian inference.\n\nIn this tutorial, we\u2019ll explore how to implement and compare VI techniques in PyMC, including the Adaptive Divergence Variational Inference (ADVI) and the cutting-edge Pathfinder algorithm.\n\nStarting with simple models like linear regression, we\u2019ll gradually introduce more complex, real-world applications, comparing the performance of VI against Markov Chain Monte Carlo (MCMC) to understand the trade-offs in speed and accuracy.\n\nThis tutorial will arm participants with practical tools to deploy VI in their workflows and help answer pressing questions, like \"What do I do when MCMC is too slow?\", or \"How does VI compare to MCMC in terms of approximation quality?\".",
  "duration": 5357,
  "language": "eng",
  "recorded": "2025-04-18",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/virginia2025"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    }
  ],
  "speakers": [
    "Chris Fonnesbeck"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/XECLmgnS6Ng/maxresdefault.jpg",
  "title": "A Beginner's Guide to Variational Inference",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=XECLmgnS6Ng"
    }
  ]
}
