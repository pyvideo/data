{
  "description": "Multi-armed bandits are a reinforcement learning tool often used in environments where the cost or rewards of different choices are unknown or where those functions may change over time. The good news is that as far as implementation goes, bandits are surprisingly easy to implement; however, in practice, the difficulty comes from defining a reward function that best targets your specific use case. In this talk, we will discuss how to use bandit algorithms effectively, taking note of practical strategies for experimental design and deployment of bandits in your applications.",
  "duration": 1819,
  "language": "eng",
  "recorded": "2025-04-18",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/virginia2025"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    }
  ],
  "speakers": [
    "Benjamin Bengfort"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/jP978VKBl-w/maxresdefault.jpg",
  "title": "Practical Multi Armed Bandits",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=jP978VKBl-w"
    }
  ]
}
