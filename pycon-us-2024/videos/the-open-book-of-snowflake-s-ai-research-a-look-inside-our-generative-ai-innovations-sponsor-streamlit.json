{
    "copyright_text": "CC BY",
    "description": "As AI becomes more crucial in our daily lives, transparency in AI models\nis vital. However, many Large Language Model (LLM) systems keep crucial\ninformation to train large language models at scale proprietary,\ncontradicting the principles of openness that define the Python\necosystem.\n\nThis session invites you to explore how Snowflake's AI research team\nimplements openness in building and sharing generative AI developments,\nprioritizing simplicity and ease-of-use while maintaining efficiency at\nscale.\n\nIn this talk, you\u2019ll learn:\n\n-  How open tools, practices, datasets, and recipes contribute to and\n   inform our research\n-  The recipes we used \u2013 including what worked and what didn\u2019t \u2013 when\n   training LLMs\n-  Developer-first example use cases of prompting, retrieval, and\n   presentation using the datasets, embeddings, and model trainings we\n   developed\n",
    "language": "eng",
    "recorded": "2024-05-16",
    "related_urls": [
        {
            "label": "Conference Website",
            "url": "https://us.pycon.org/2024/"
        },
        {
            "label": "Presentation Webpage",
            "url": "https://us.pycon.org/2024/schedule/presentation/161/"
        }
    ],
    "speakers": [
        "Yusuf Ozuysal"
    ],
    "thumbnail_url": "https://i.ytimg.com/vi/15GKU5SODv8/hqdefault.jpg",
    "title": "The open book of Snowflake's AI research: A look inside our generative AI innovations (Sponsor: Streamlit)",
    "videos": [
        {
            "type": "youtube",
            "url": "https://www.youtube.com/watch?v=15GKU5SODv8"
        }
    ]
}