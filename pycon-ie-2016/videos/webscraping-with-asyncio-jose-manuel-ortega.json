{
  "description": "If we want to extract the contents of a website automating information\nextraction, often we find that the website does not offer any API to\nget the data you need and it is necessary use scraping techniques to\nrecover data from a Web automatically. Some of the most powerful tools\nfor extracting the data in web pages can be found in python ecosystem.\n\n1. Introduction to webscraping and python tools\n\n    Some of the most powerful tools to extract data can be found in the\n    python ecosystem, among which we highlight Beautiful soup, Pyquery and\n    Scrapy.\n\n2. Asyncio with aiohttp for asyncronous requests\n\n    I will make an introduction to asyncio and aiohttp modules explaining\n    the basic concepts like coroutines and event loops and try to compare\n    them with requests module. The most important is understand why the\n    union asyncio + aiohttp has a better performance than requests module.\n\n3. Asynchronous scraping data\n\n    I will show an example integrating some of the scraping tools\n    commented before like BeautifulSoup or Scrapy with asyncio + aiohttp\n    and obtain the performance improvement comparing with Requests module.\n",
  "duration": 3018,
  "recorded": "2016-11-06",
  "speakers": [
    "Jose Manuel Ortega"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/IV-DzaOUCKc/hqdefault.jpg",
  "title": "Webscraping with Asyncio",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=IV-DzaOUCKc"
    }
  ]
}
