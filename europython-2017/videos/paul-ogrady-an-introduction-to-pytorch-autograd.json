{
  "description": "PyTorch is an optimized tensor library for Deep Learning, and is a\nrecent newcomer to the growing list of GPU programming frameworks\navailable in Python. Like other frameworks it offers efficient tensor\nrepresentations and is agnostic to the underlying hardware. However,\nunlike other frameworks it allows you to create \"define-by-run\"\nneural networks resulting in dynamic computation graphs, where every\nsingle iteration can be different---opening up a whole new world of\npossibilities. Central to all neural networks in PyTorch is the\nAutograd package, which performs Algorithmic Differentiation on the\ndefined model and generates the required gradients at each iteration.\nIn this talk I will present a gentle introduction to the PyTorch\nlibrary and overview its main features using some simple examples,\npaying particular attention to the mechanics of the Autograd package.\n\nKeywords: GPU Processing, Algorithmic Differentiation, Deep Learning, Linear algebra.",
  "duration": 1911,
  "recorded": "2017-07-13",
  "speakers": [
    "Paul O'Grady"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/rrekAv9Fml4/hqdefault.jpg",
  "title": "An introduction to PyTorch & Autograd",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=rrekAv9Fml4"
    }
  ]
}
