{
  "copyright_text": "",
  "description": "ML models often act as black boxes, making it hard to extract actionable insights. SHAP helps explain predictions by attributing importance to input features using concepts from game theory. In this talk, we\u2019ll cover the need for explainability, introduce the intuition behind Shapley values, and walk through a couple of case studies using boosted tree-based and neural network based models. We\u2019ll also discuss SHAP plots, best practices, challenges, and pitfalls when working with large datasets.",
  "duration": 1841,
  "language": "eng",
  "recorded": "2025-10-18",
  "related_urls": [
    {
      "label": "Conference schedule",
      "url": "https://pybay.org/speaking/schedule/"
    },
    {
      "label": "Full playlist",
      "url": "https://www.youtube.com/playlist?list=PL85KuAjbN_gseSuHZTUCgNAHLeKuMDBxI"
    }
  ],
  "speakers": [
    "Avik Basu"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/AfEfu6o-ACI/maxresdefault.webp",
  "title": "Beyond the Black Box: Interpreting ML models with SHAP",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=AfEfu6o-ACI"
    }
  ]
}
