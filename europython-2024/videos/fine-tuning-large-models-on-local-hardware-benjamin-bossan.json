{
  "description": "[EuroPython 2024 \u2014 Forum Hall on 2024-07-11]\n\n\rFine-tuning large models on local hardware by Benjamin Bossan\n\rhttps://ep2024.europython.eu/session/fine-tuning-large-models-on-local-hardware\n\n\rFine-tuning big neural nets like Large Language Models (LLMs) has traditionally been prohibitive due to high hardware requirements. However, Parameter-Efficient Fine-Tuning (PEFT) and quantization enable the training of large models on modest hardware. Thanks to the PEFT library and the Hugging Face ecosystem, these techniques are now accessible to a broad audience.\n\n\rExpect to learn:\n\n\r- what the challenges are of fine-tuning large models\n\r- what solutions have been proposed and how they work\n\r- practical examples of applying the PEFT library\n\n\n\r---\n\rThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License: https://creativecommons.org/licenses/by-nc-sa/4.0/",
  "duration": 1678,
  "language": "eng",
  "recorded": "2024-07-08",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://ep2024.europython.eu/"
    },
    {
      "label": "https://ep2024.europython.eu/session/fine-tuning-large-models-on-local-hardware",
      "url": "https://ep2024.europython.eu/session/fine-tuning-large-models-on-local-hardware"
    },
    {
      "label": "https://creativecommons.org/licenses/by-nc-sa/4.0/",
      "url": "https://creativecommons.org/licenses/by-nc-sa/4.0/"
    }
  ],
  "speakers": [
    "Benjamin Bossan"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/hdHKCjhF68U/maxresdefault.jpg",
  "title": "Fine-tuning large models on local hardware",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=hdHKCjhF68U"
    }
  ]
}
