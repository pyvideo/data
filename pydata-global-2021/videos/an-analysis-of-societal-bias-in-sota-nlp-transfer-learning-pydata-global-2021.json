{
  "description": "An Analysis of Societal Bias in Sota NLP Transfer Learning\nSpeakers: Benjamin Ajayi-Obe, David Hopes\n\nSummary\nThe popularisation of large pre-trained language models has resulted in their increased adoption in commercial settings. However, these models are usually pre-trained on raw, unprocessed corpora that are known to contain a plethora of societal biases. In this talk, we explore the sources of this bias, as well as recent methods of measuring and mitigating it.\n\nDescription\nSince the publication of Google\u2019s seminal paper, \u201cAttention is all you need\u201d, attention based transformers have become widely celebrated and adopted for their impressive ability to emulate human-like text. However, it has become increasingly evident that, while these models are very capable of modelling text from a large corpus, they also embed societal biases present in the data. These biases can be difficult to detect unless intentionally inspected for or documented, and so they pose a real risk to organisations who wish to make use of state of the art NLP models, particularly those who have limited budgets to retrain them. This talk is for anyone who wishes to deepen their understanding of attention based transformers from an ethical standpoint and also those looking to deploy attention based models in a commercial setting. You will leave with a better understanding of the types of biases that pose a risk to attention based models, the source of this bias and potential strategies for mitigating against it. For this talk we presume the audience has a high level understanding of neural networks and some knowledge of linear algebra. The first 15 minutes will be a discussion around the types of bias that pose a risk to these models as well as some demonstrations of biased outputs. The second 15 minutes will be an exploration into strategies to detect and mitigate against these biases.\n\nBenjamin Ajayi-Obe's Bio\nI am a data scientist in the ranking and recommendation team of Depop. I am interested in the the development and application of NLP models for commercial use. I am also interested in the ethical implications of deploying AI solutions in the real world and exploring ways of ensuring fairness, equity and safety in a society that is increasingly adopting ML.\nGitHub: https://github.com/BenAjayiObe/\nTwitter: https://twitter.com/BOA4/\nLinkedIn: https://www.linkedin.com/in/benjamin-ajayi-obe-14183073/\n\nDavid Hopes's Bio\nData scientist and ethical AI ambassador at Depop, currently focusing on ML solutions for the marketing technology team. Research interests in computational pragmatics and context in communication.\nGitHub: https://github.com/davidhopes/\nTwitter: https://twitter.com/davidghopes/\nLinkedIn: https://www.linkedin.com/in/davidhopes/\n\nPyData Global 2021\nWebsite: https://pydata.org/global2021/\nLinkedIn: https://www.linkedin.com/company/pydata-global\nTwitter: https://twitter.com/PyData\n\nwww.pydata.org\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.\n\n00:00 Welcome!\n00:10 Help us add time stamps or captions to this video! See the description for details.\n\nWant to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVideoTimestamps",
  "duration": 1830,
  "language": "eng",
  "recorded": "2021-10-28",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/global2021/"
    },
    {
      "label": "https://www.linkedin.com/company/pydata-global",
      "url": "https://www.linkedin.com/company/pydata-global"
    },
    {
      "label": "https://www.linkedin.com/in/benjamin-ajayi-obe-14183073/",
      "url": "https://www.linkedin.com/in/benjamin-ajayi-obe-14183073/"
    },
    {
      "label": "https://github.com/davidhopes/",
      "url": "https://github.com/davidhopes/"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    },
    {
      "label": "https://github.com/BenAjayiObe/",
      "url": "https://github.com/BenAjayiObe/"
    },
    {
      "label": "https://www.linkedin.com/in/davidhopes/",
      "url": "https://www.linkedin.com/in/davidhopes/"
    },
    {
      "label": "https://twitter.com/PyData",
      "url": "https://twitter.com/PyData"
    },
    {
      "label": "https://twitter.com/BOA4/",
      "url": "https://twitter.com/BOA4/"
    },
    {
      "label": "https://twitter.com/davidghopes/",
      "url": "https://twitter.com/davidghopes/"
    },
    {
      "label": "https://pydata.org/global2021/",
      "url": "https://pydata.org/global2021/"
    }
  ],
  "speakers": [
    "TODO"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/hGQGxmqkKlE/maxresdefault.jpg",
  "title": "An Analysis of Societal Bias in Sota NLP Transfer Learning | PyData Global 2021",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=hGQGxmqkKlE"
    }
  ]
}
