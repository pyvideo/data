{
  "description": "Counter Factual Analysis for Explainable AI\nSpeaker: Shashank Shekhar\n\nSummary\nAI models are getting increasingly advanced and so is the need of explaining them. Counter Factual Analysis (CFA) explores outcomes that did not actually occur, but which could have occurred under different set of conditions. In this talk, I will discuss the theoretical aspects of CFA, state-of-the-art algorithms, and its relationship with feature attribution methods like Shapley Values.\n\nDescription\nThe talk will be delivered in three parts.\nPart \u2013 I: Introduction to Counter Factual Analysis - 10 minutes\nThis part discusses the following concepts\n- Definition of counter factual explanations and its significance\n-  The desirable properties for actionable counter factual generation and related optimization challenges\n- Brief discussion on CF explanation generation methods\n- Introduction to state-of-the-art algorithms\nPart \u2013 II: Introduction to CFA tools - 10 minutes\nIn this part, I will walk through a use case using state-of-the-art tools. Following tools will be introduced.\n- DICE - This tool is introduced by Microsoft. Unlike many methods, it gives the options to generate multiple number of CF instances and control for users in modifying features.\n- Alibi - Alibi is a general-purpose explainable AI (XAI) tool. We will briefly discuss the CFs generated by class prototypes provided in the tool.\nPart \u2013 III: Research Directions - 10 minutes\nIn this part, I will briefly discuss about the further research directions in CFA and two related XAI paradigms.\n- Relation between CFE methods and feature attribution methods such as Shapley values and LIME.\n- Checking ethical aspects of AI using CFEs.\n\nShashank Shekhar's Bio\nShashank is Data Sciences leader with diverse experience across verticals including Telecom, CPG, Retail, Hitech and E-commerce domains. He is currently heading the Artificial Intelligence Labs at Subex. In the past, he has worked in VMware, Amazon, Flipkart and Target and has been involved in solving various complex business problems using Machine Learning and Deep Learning. He has been part of the program committee of several international conferences like ICDM and MLDM and was selected as a mentor in Global Datathon 2018 organized by Data Sciences Society. He has multiple publications in the field of artificial intelligence, machine learning, deep learning and image recognition in several international journals of repute to his credit. He has spoken at many summits and conferences like APAC Data Innovation Summit, Big Data Lake Summit, PlugIn etc. He has also published three open source libraries on Python and is an active contributor to the global Python community.\nGitHub: https://github.com/quintshekhar/\nLinkedIn: https://www.linkedin.com/in/shashank-shekhar-748a4a12/\n\nPyData Global 2021\nWebsite: https://pydata.org/global2021/\nLinkedIn: https://www.linkedin.com/company/pydata-global\nTwitter: https://twitter.com/PyData\n\nwww.pydata.org\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.\n\n00:00 Welcome!\n00:10 Help us add time stamps or captions to this video! See the description for details.\n\nWant to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVideoTimestamps",
  "duration": 1625,
  "language": "eng",
  "recorded": "2021-10-28",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/global2021/"
    },
    {
      "label": "https://www.linkedin.com/company/pydata-global",
      "url": "https://www.linkedin.com/company/pydata-global"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    },
    {
      "label": "https://github.com/quintshekhar/",
      "url": "https://github.com/quintshekhar/"
    },
    {
      "label": "https://www.linkedin.com/in/shashank-shekhar-748a4a12/",
      "url": "https://www.linkedin.com/in/shashank-shekhar-748a4a12/"
    },
    {
      "label": "https://twitter.com/PyData",
      "url": "https://twitter.com/PyData"
    },
    {
      "label": "https://pydata.org/global2021/",
      "url": "https://pydata.org/global2021/"
    }
  ],
  "speakers": [
    "Shashank Shekhar"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/DgzyKrLxIaU/maxresdefault.jpg",
  "title": "Counter Factual Analysis for Explainable AI",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=DgzyKrLxIaU"
    }
  ]
}
