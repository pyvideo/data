{
  "description": "Selecting the optimal set of features is a key step in the ML modeling\nprocess. This talk will present research conducted that tested five\napproaches for feature selection. The approaches included current widely\nused methods, along with novel approaches for feature selection using\nopen-source libraries, building a classification model using the Lending\nClub dataset.\n\nA central component to the Machine Learning process is feature\nselection. Selecting the optimal set of features is important to\ngenerate a best fit model which generalizes to unseen data. A widely\nused approach for feature selection involves calculating Gini Importance\n(Gain) to identify the best set of features. However, recent work from\nScott Lundberg has found challenges with the consistency of the Gain\nattribution method. This talk will present results of model metrics on\nthe Lending Club dataset, testing five different feature selection\napproaches. The approaches tested involved widely used approaches\ncombined with novel approaches for feature selection.\n\nThrough the experimental design of the five feature selection approaches\nthat were tested; attendees will gain clarity on the impact of:\n\n-  Data splitting method\n-  Including relevant two-way and three-way interactions (xgbfir\n   library)\n-  Backwards stepwise feature selection as opposed to a singular feature\n   selection step\n-  Backwards stepwise feature selection using Shapley values (shap\n   library).\n\nThe knowledge from this research can provide added predictive power and\nvelocity to the feature selection process for Data Scientists.\n",
  "duration": 1806,
  "published_at": "2019-12-23T21:03:35.000Z",
  "recorded": "2019-12-04",
  "speakers": [
    "Ben Fowler"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/rQd5nzktKz0/hqdefault.jpg",
  "title": "Evaluation of Traditional and Novel Feature Selection Approaches",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=rQd5nzktKz0"
    }
  ]
}
