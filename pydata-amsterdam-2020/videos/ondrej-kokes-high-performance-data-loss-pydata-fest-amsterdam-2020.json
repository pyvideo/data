{
  "description": "PyData is excited to announce PyData Global, November 11th - 15th! Tickets are now available: https://global.pydata.org/pages/tickets.html#pricing-and-ticket-purchases\nPart of an underrepresented group in tech? PyData Global is offering Diversity Scholarships. Applications close September 30th: https://docs.google.com/forms/d/e/1FAIpQLSfcFaTqVFjMa6kWlLPeEynEcbp1WrCxyxMGyyh4BP33eAviaA/viewform\n\n\nOndrej Kokes - High Performance Data Loss | PyData Fest Amsterdam 2020\n\nSay I give you a CSV with business orders, there are just three of them, the business is just taking off. Pandas tells you the average purchase is for $45, but you can equally use Excel, which gives you the same answer. In anticipation of a rosy future, you decide to use a Big Data Tool. You load it up and process the very same CSV and you report the business is actually doing thousands of orders for millions of dollars.\n\nWhat is this sorcery? Did I just hijack your analysis by \u201chacking\u201d a CSV? Are big data tools broken? Can this happen in reality?\n\nWith the emergence of big-ish data, lots of tech has focused on the performance side of things. While more performance should be better than less performance, it\u2019s not all roses. When evaluating these technologies, we\u2019ve often stumbled upon integrity issues, sometimes to leading massive data losses. Or, as illustrated above, it can lead to strange data\u2026 gains.\n\nIn this talk, I\u2019ll go over several implementation details that can lead to a large data loss without triggering any warnings or errors. We\u2019ll go over a few cases (with data and code examples), but the main ideas are as follows:\n\ncorrectness should always trump performance - always make sure you\u2019re getting the right results, only then focus on performance \u201cexplicit is better than implicit\u201d - this Zen of Python quote is not just about code clarity, it\u2019s useful when using data processing tools with hidden logic fail early, fail often - would you like a pipeline that never fails, but produces garbage, or would you prefer to be paged every now and then, because of an issue? The main takeaway is that you should understand the abstractions you\u2019re using to process your data, no matter what your role is. Every single step that is there between a data source and your report/analysis/database/sink should be understandable, predictable, and, most importantly, correct. After all, our job as data guardians is to deliver data things reliably and correctly - our customer doesn\u2019t care if it\u2019s in the shiniest new Apache tool or in Cobol, orchestrated by Ada.\n\n\nwww.pydata.org\r\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \r\n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases. 00:00 Welcome!\n00:10 Help us add time stamps or captions to this video! See the description for details.\n\nWant to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVideoTimestamps",
  "duration": 1749,
  "language": "eng",
  "recorded": "2020-06-15",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://datasciencedistrict.nl/pydata-festival-amsterda/"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    },
    {
      "label": "https://docs.google.com/forms/d/e/1FAIpQLSfcFaTqVFjMa6kWlLPeEynEcbp1WrCxyxMGyyh4BP33eAviaA/viewform",
      "url": "https://docs.google.com/forms/d/e/1FAIpQLSfcFaTqVFjMa6kWlLPeEynEcbp1WrCxyxMGyyh4BP33eAviaA/viewform"
    },
    {
      "label": "https://global.pydata.org/pages/tickets.html#pricing-and-ticket-purchases",
      "url": "https://global.pydata.org/pages/tickets.html#pricing-and-ticket-purchases"
    }
  ],
  "speakers": [
    "Ondrej Kokes"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/hoaMzebS_l4/maxresdefault.webp",
  "title": "High Performance Data Loss",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=hoaMzebS_l4"
    }
  ]
}
