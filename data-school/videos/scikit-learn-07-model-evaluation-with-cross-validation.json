{
  "copyright_text": "Standard YouTube License",
  "description": "In this video, we'll learn about K-fold cross-validation and how it can be used for selecting optimal tuning parameters, choosing between models, and selecting features. We'll compare cross-validation with the train/test split procedure, and we'll also discuss some variations of cross-validation that can result in more accurate estimates of model performance.\n\nThis is the seventh video in the series, `Introduction to machine learning with scikit-learn <http://www.dataschool.io/machine-learning-with-scikit-learn/>`__. The notebook and resources shown in the video are available on `GitHub <https://github.com/justmarkham/scikit-learn-videos>`__.",
  "duration": 2153,
  "language": "eng",
  "recorded": "2015-06-28",
  "related_urls": [
    "http://www.dataschool.io/machine-learning-with-scikit-learn/",
    "https://github.com/justmarkham/scikit-learn-videos"
  ],
  "slug": "scikit-learn-07-model-evaluation-with-cross-validation",
  "speakers": [
    "Kevin Markham"
  ],
  "tags": [
    "machine learning",
    "data science",
    "scikit-learn",
    "tutorial",
    "Data School",
    "cross-validation",
    "model evaluation",
    "feature selection",
    "parameter tuning"
  ],
  "thumbnail_url": "https://i1.ytimg.com/vi/6dbrR-WymjI/maxresdefault.jpg",
  "title": "Selecting the best model in scikit-learn using cross-validation",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=6dbrR-WymjI"
    }
  ]
}
