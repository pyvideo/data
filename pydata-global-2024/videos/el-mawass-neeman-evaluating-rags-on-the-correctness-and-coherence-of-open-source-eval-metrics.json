{
  "description": "Retrieval-Augmented Generation (RAG), despite being a superstar of GenAI over the last year, comes with a plethora of challenges and is prone to errors. Open Source Python libraries like RAGAS and TruLens provide frameworks for evaluating RAG systems, using various metrics that leverage LLMs to assess performance. But when using LLM in a RAG system is in itself a source of errors, it remains to be seen how reliable it would be to use another LLM, allthebit a more powerful one, as a judge of the RAG performance. This study explores various RAG evaluation metrics, as well as the choice of evaluator LLM, to examine the reliability and consistency of LLM-based evaluations. The aim is to provide practical insights and guidance for interpreting these evaluations effectively, and help users make informed decisions when applying them in diverse contexts.\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.",
  "duration": 1807,
  "language": "eng",
  "recorded": "2024-12-03",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/global2024"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    }
  ],
  "speakers": [
    "Nour El Mawass",
    "Joe Neeman"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/hCCJoJ5URD0/maxresdefault.jpg",
  "title": "Evaluating RAGs: On the correctness and coherence of Open Source eval metrics",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=hCCJoJ5URD0"
    }
  ]
}
