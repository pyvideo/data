{
  "description": "Retrieval-augmented generation (RAG) has become a key application for large language models (LLMs), enhancing their responses with information from external databases. However, RAG systems are prone to errors, and their complexity has made evaluation a critical and challenging area. Various libraries (like RAGAS and TruLens) have introduced evaluation tools and metrics for RAGs, but these evaluations involve using one LLM to assess another, raising questions about their reliability. Our study examines the stability and usefulness of these evaluation methods across different datasets and domains, focusing on the effects of the choice of the evaluation LLM, query reformulation, and dataset characteristics on RAG performance. It also assesses the stability of the metrics on multiple runs of the evaluation and how metrics correlate with each other. The talk aims to guide users in selecting and interpreting LLM-based evaluations effectively.\n\nhttps://github.com/tweag/pydata-paris-2024-slides\n\nwww.pydata.org\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.\n\n00:00 Welcome!\n00:10 Help us add time stamps or captions to this video! See the description for details.\n\nWant to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVideoTimestamps",
  "duration": 1790,
  "language": "eng",
  "recorded": "2024-09-25",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/paris2024"
    },
    {
      "label": "https://github.com/tweag/pydata-paris-2024-slides",
      "url": "https://github.com/tweag/pydata-paris-2024-slides"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    }
  ],
  "speakers": [
    "TODO"
  ],
  "tags": [
    "Education",
    "Julia",
    "NumFOCUS",
    "Opensource",
    "PyData",
    "Python",
    "Tutorial",
    "coding",
    "how to program",
    "learn",
    "learn to code",
    "python 3",
    "scientific programming",
    "software"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/yrWmK3pXrKk/sddefault.jpg",
  "title": "El Mawass & Knorps - Evaluating the evaluator- RAG eval libraries under the loop | PyData Paris 2024",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=yrWmK3pXrKk"
    }
  ]
}
