{
  "description": "PyData\nWebsite: www.pydata.org\nLinkedIn: https://www.linkedin.com/company/pydata-global\nTwitter: https://twitter.com/PyData\n\nThis talk will highlight common pitfalls that occur when evaluating Machine Learning (ML) and Natural Language Processing (NLP) approaches. It will provide comprehensive advice on how to set up a solid evaluation procedure in general, and dive into a few specific use-cases to demonstrate artificial bias that unknowingly can creep in. It will tell the story hidden behind the performance numbers, and get the audience into the right critical mindset to run unbiased evaluations and data analyses for their own projects.\n\nWith AI technology booming, the entry barrier to using ML/NLP in applications is continuously decreasing thanks to the release of novel open-source libraries, pretrained LLM/transformer models, and convenient API access for all. It has never been easier to integrate ML or NLP models into a commercial product or research application. As a consequence, the need for meaningful evaluation of these techniques to specific use-cases and domains has only become more pressing, both for developers as well as for users of these AI tools.\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.\n\n00:00 Welcome!\n00:10 Help us add time stamps or captions to this video! See the description for details.\n\nWant to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVideoTimestamps",
  "duration": 2342,
  "language": "eng",
  "recorded": "2024-06-14",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/london2024/"
    },
    {
      "label": "https://www.linkedin.com/company/pydata-global",
      "url": "https://www.linkedin.com/company/pydata-global"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    },
    {
      "label": "https://twitter.com/PyData",
      "url": "https://twitter.com/PyData"
    }
  ],
  "speakers": [
    "TODO"
  ],
  "tags": [
    "Education",
    "Julia",
    "NumFOCUS",
    "Opensource",
    "PyData",
    "Python",
    "Tutorial",
    "coding",
    "how to program",
    "learn",
    "learn to code",
    "python 3",
    "scientific programming",
    "software"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/4gcGkFAG7OA/maxresdefault.jpg",
  "title": "Sofie Van Landeghem- How to Avoid structural biases in evaluating your Machine Learning/NLP projects",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=4gcGkFAG7OA"
    }
  ]
}
