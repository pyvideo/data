{
  "description": "\"We  propose   the  Generalized   Policy  Elimination  (GPE)   algorithm,  an\n  oracle-efficient  contextual bandit  (CB) algorithm  inspired by  the Policy\n  Elimination   algorithm   of   \\cite{dudik2011}.    We   prove   the   first\n  regret-optimality  guarantee theorem  for an  oracle-efficient CB  algorithm\n  competing  against   a  nonparametric  class  with   infinite  VC-dimension.\n  Specifically, we show that GPE is regret-optimal (up to logarithmic factors)\n  for policy classes with integrable entropy.\n\n  For classes  with larger entropy, we  show that the core  techniques used to\n  analyze GPE  can be  used to design  an $\\varepsilon$-greedy  algorithm with\n  regret bound  matching that of the  best algorithms to date.   We illustrate\n  the  applicability of  our algorithms  and theorems  with examples  of large\n  nonparametric policy  classes, for  which the relevant  optimization oracles\n  can be efficiently implemented.\"",
  "duration": 487,
  "language": "eng",
  "recorded": "2020-08-03",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://www.auai.org/uai2020/"
    }
  ],
  "speakers": [
    "Aurelien Bibaut",
    "Antoine Chambaz",
    "Mark van der Laan"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/UscD_8WQ0Rc/sddefault.jpg",
  "title": "Generalized Policy Elimination: an efficient algorithm for Nonparametric Contextual Bandits",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=UscD_8WQ0Rc"
    }
  ]
}
