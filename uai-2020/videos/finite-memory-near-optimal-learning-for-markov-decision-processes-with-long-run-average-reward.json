{
  "description": "\"Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward\n\nJan Kretinsky (TU Munich)*; Fabian Michel (TU Munich); Lukas Michel (TU Munich); Guillermo Perez (UAntwerpen)\n\nWe consider learning policies online in Markov decision processes with the long-run average reward (a.k.a. mean payoff). To ensure implementability of the policies, we focus on policies with finite memory. Firstly, we show that near optimality can be achieved almost surely, using an unintuitive gadget we call forgetfulness. Secondly, we extend the approach to a setting with partial knowledge of the system topology, introducing two optimality measures and providing near-optimal algorithms also for these cases.\"",
  "duration": 480,
  "language": "eng",
  "recorded": "2020-08-03",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://www.auai.org/uai2020/"
    }
  ],
  "speakers": [
    "Jan Kretinsky",
    "Fabian Michel",
    "Lukas Michel",
    "Guillermo Perez"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/dHsHAplui-w/sddefault.jpg",
  "title": "Finite-Memory Near-Optimal Learning for Markov Decision Processes with Long-Run Average Reward",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=dHsHAplui-w"
    }
  ]
}
