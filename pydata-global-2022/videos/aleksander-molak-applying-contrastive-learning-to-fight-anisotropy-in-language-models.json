{
  "description": "www.pydata.org\n\nTransformer models became state-of-the-art in natural language processing. Word representations learned by these models offer great flexibility for many types of downstream tasks from classification to summarization. Nonetheless, these representations suffer from certain conditions that impair their effectiveness. Researchers have demonstrated that BERT and GPT embeddings tend to cluster in a narrow cone of the embedding space which leads to unwanted consequences (e.g. spurious similarities between unrelated words). During the talk we\u2019ll introduce SimCSE \u2013 a contrastive learning method that helps to regularize the embeddings and reduce the problem of anisotropy. We will demonstrate how SimCSE can be implemented in Python.\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.\n\n00:00 Welcome!\n00:10 Help us add time stamps or captions to this video! See the description for details.\n\nWant to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVideoTimestamps",
  "duration": 1563,
  "language": "eng",
  "recorded": "2022-12-01",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/global2022/"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    }
  ],
  "speakers": [
    "Aleksander Molak"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/IdI3ccktbKw/maxresdefault.jpg",
  "title": "Applying contrastive learning to fight anisotropy in language models",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=IdI3ccktbKw"
    }
  ]
}
