{
  "description": "Speaker:: Steven Kolawole\n\nTrack: PyData: Computer Vision\nBuilding an E2E working prototype that detects sign language meanings in images/videos and generates equivalent, realistic voice of words communicated by the sign language, in real-time, won't be completed in a day's work. Here I'd explain how it happened and what I learned in the process.\n\n\nRecorded at the PyConDE & PyData Berlin 2022 conference, April 11-13 2022.\nhttps://2022.pycon.de\nMore details at the conference page: https://2022.pycon.de/program/WWPUGX\nTwitter: https://twitter.com/pydataberlin\nTwitter: https://twitter.com/pyconde",
  "duration": 1567,
  "language": "eng",
  "recorded": "2022-04-11",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://2022.pycon.de/"
    },
    {
      "label": "https://2022.pycon.de/program/WWPUGX",
      "url": "https://2022.pycon.de/program/WWPUGX"
    },
    {
      "label": "https://2022.pycon.de",
      "url": "https://2022.pycon.de"
    },
    {
      "label": "https://twitter.com/pyconde",
      "url": "https://twitter.com/pyconde"
    },
    {
      "label": "https://twitter.com/pydataberlin",
      "url": "https://twitter.com/pydataberlin"
    }
  ],
  "speakers": [
    "TODO"
  ],
  "tags": [
    "artificial intelligence",
    "data",
    "data engineering",
    "deep learning",
    "ethics",
    "machine learning",
    "python"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/X9JwoWccpYI/maxresdefault.webp",
  "title": "Steven Kolawole: Building a Sign-to-Speech prototype with TensorFlow, Pytorch and DeepStack: How...",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=X9JwoWccpYI"
    }
  ]
}
