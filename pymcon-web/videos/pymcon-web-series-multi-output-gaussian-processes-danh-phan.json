{
  "description": "Welcome to to the second event from the PyMCon Web Series. \n\nTo learn about upcoming events check out the website: https://pymcon.com/events/\n\nMulti-output Gaussian processes have recently gained strong attention from researchers and have become an active research topic in machine learning\u2019s multi-task learning. The advantage of multi-output Gaussian processes is their capacity to simultaneously learn and infer many outputs which have a similar source of uncertainty from inputs.\n\nFor the full details see the PyMC Discourse.\n\nhttps://discourse.pymc.io/t/pymcon-web-series-an-introduction-to-multi-output-gaussian-processes-using-pymc-feb-21st-10-pm-utc-2023/11395/11\n\n## Timestamps\n00:00 Ravin Kumar does introduction and background\n02:18 Danh Phan instructions on using the workshop's repo\n05:47 Part 1: Introduction to Gaussian processes (GPs) with PyMC\n05:48 1.0 Intro\n06:54 1.1 Bayesian Linear Regression\n11:43 1.2 Gaussian Process\n13:20 1.3 GP Mean and Covariance Functions\n16:24 1.3 examples\n15:56 2.0 Model implementation in PyMC\n16:57 2.1 Bayesian Linear Regression\n19:52 2.2 Gaussian Processes in PyMC\n24:27 3.0 References\n25:12 Q&A for Part 1\n28:03 Part 2: Introduction to Multi-output Gaussian processes (MoGPs) with PyMC\n28:18 1.0 Why MoGPs\n31:08 1.1 Single-output Gaussian Process\n32:31 1.2 Multiple-output Gaussian Process\n34:53 2.0 Intrinsic Coregionalization Model (ICM)\n36:00 2.1 ICM: one latent samples & covariance\n39:21 2.2 ICM: two outputs, two laten samples & covariance\n42:25 2.3 Kronecker product between matrices\n43:58 2.4 ICM: covariances as Kronecker product\n44:37 3.0 Linear Coregionalization Model (LCM)\n45:11 3.1 LCM: covariance\n45:41 4.0 PyMC Coregion kernel\n46:18 5.0 Hadamard product between matrices\n47:07 5.1 Kronecker to Hadamard product\n49:52 Part 2 example: Intro\n50:07 Part 2 example: Data prep & EDA\n51:40 Part 2 example: ICM\n56:39 Part 2 example: LCM\n58:42 Author's example work\n01:00:42 Sampling with nutpie\n01:02:23 Q&A for part 2: How important the joint normality assumption (in enquirer's work)\n01:04:47 Q&A for part 2: Business benefits of using MoGPs in the baseball example\n01:11:07 Q&A for part 2: Validity of using MoGPs for sparse temporal data (crime)\n01:13:43 Ravin Kumar closing",
  "duration": 4459,
  "language": "eng",
  "recorded": "2023-02-27",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pymcon.com/"
    },
    {
      "label": "https://pymcon.com/events/",
      "url": "https://pymcon.com/events/"
    },
    {
      "label": "https://discourse.pymc.io/t/pymcon-web-series-an-introduction-to-multi-output-gaussian-processes-using-pymc-feb-21st-10-pm-utc-2023/11395/11",
      "url": "https://discourse.pymc.io/t/pymcon-web-series-an-introduction-to-multi-output-gaussian-processes-using-pymc-feb-21st-10-pm-utc-2023/11395/11"
    }
    ,
    {
      "label": "Speaker Interview",
      "url": "https://www.youtube.com/watch?v=cyJkqnCU1-I"
    }
  ],
  "speakers": [
    "Danh Phan"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/8YN7dLJlHIE/maxresdefault.webp",
  "title": "Multi Output Gaussian Processes",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=8YN7dLJlHIE"
    }
  ]
}
