{"whiteboard": "", "video_mp4_download_only": false, "video_webm_download_only": false, "duration": null, "video_ogv_download_only": false, "category": "PyCon APAC 2014", "speakers": ["Wisely Chen"], "title": "PySpark: next generation cluster computing engine", "quality_notes": "", "video_flv_length": null, "recorded": "2014-06-24", "video_mp4_length": null, "description": "Apache Spark\u2122 is a lightning fast engine for large-scale data processing. It is an in-memory cluster computing framework, originally developed in UC Berkeley. Base on it's project page's evaluation, machine learning programming can run program 100x faster than Hadoop MapReduce. And Spark can run on Hadoop 2's YARN cluster manager, and can read any existing Hadoop data. Currently, it supports Scala, Java and Python for writing spark programs. \r\n\r\nIn this talk, I will introduce the General concept of Spark's infrastructure, What is RDD (Resilient Distributed Datasets) in Spark, Introduction on PySpark, Demo of PySpark's speed and power, Head-to-head comparison between two programs doing same work - one written in Hadoop MapReduce and the other written using PySpark.\r\n\r\nI will also conclude about the companies currently using Spark's use cases.\r\n\r\n\r\nAbout the speaker\r\n\r\nSr. Software Engineer for the Yahoo! (Taiwan) Data Team. He has been responsible for data infrastructure, data solution, software release and continuous integration management. He is a lifelong student of software development/testing/deployment/CI processes and best practices and an avid coding puzzle competition fanatic as well as Open Source evangelist", "video_mp4_url": "", "tags": [], "copyright_text": "youtube", "related_urls": [], "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=gaR7svYX8pw", "video_webm_url": "", "video_ogv_length": null, "video_ogv_url": "", "language": "English", "video_webm_length": null, "summary": "", "thumbnail_url": "https://i.ytimg.com/vi/gaR7svYX8pw/hqdefault.jpg", "video_flv_url": ""}