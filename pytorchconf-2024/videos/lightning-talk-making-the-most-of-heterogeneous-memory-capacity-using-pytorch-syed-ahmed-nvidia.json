{
  "description": "Memory intensive deep learning workloads require efficient use of all kinds of memories that are available in a system. In this session, we will discuss how we can utilize such heterogeneous memory through memory pools in PyTorch. We will show how to mix-and-match different CUDA system allocators in the same PyTorch program using memory pools. Consequently, this API unlocks new use cases such as Extended GPU Memory (EGM) based all-gathers, Unified Virtual Memory (UVM), and NVLink Sharp (NVLS) reductions. New NVIDIA architectures accelerate such use cases with high-bandwidth and low-latency interconnects in the hardware, driven by extended functionality of CUDA system allocators in the software. Learn how to use these techniques on memory-intensive deep learning models like LLMs, and discover new CUDA features powered by PyTorch.",
  "duration": 686,
  "language": "eng",
  "recorded": "2024-09-18",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pytorch.org/event/pytorch-conference-2024/"
    }
  ],
  "speakers": [
    "Syed Ahmed"
  ],
  "tags": [
    "Lightning Talk"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/srQOK1UusZ4/maxresdefault.webp",
  "title": "Making the Most of Heterogeneous Memory Capacity Using PyTorch",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=srQOK1UusZ4"
    }
  ]
}
