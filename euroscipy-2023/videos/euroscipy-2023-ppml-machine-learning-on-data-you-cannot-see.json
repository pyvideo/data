{
  "description": "Privacy guarantee is the most crucial requirement when it comes to analyse sensitive data. However, data anonymisation techniques alone do not always provide complete privacy protection; moreover Machine Learning models could also be exploited to leak sensitive data when attacked, and no counter-measure is applied. Privacy-preserving machine learning (PPML) methods hold the promise to overcome all these issues, allowing to train machine learning models with full privacy guarantees. In this tutorial we will explore several methods for privacy-preserving data analysis, and how these techniques can be used to safely train ML models without actually seeing the data.",
  "duration": 5427,
  "language": "eng",
  "recorded": "2023-08-14",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://web.archive.org/web/20241120213156/https://euroscipy.org/2023/"
    },
    {
      "label": "Presenation Webpage",
      "url": "https://pretalx.com/euroscipy-2023/talk/7P3AYM/"
    }
  ],
  "speakers": [
    "Valerio Maggio"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/Gn5b5gt8OiA/maxresdefault.webp",
  "title": "PPML: Machine Learning on data you cannot see",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=Gn5b5gt8OiA"
    }
  ]
}
