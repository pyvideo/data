{
  "copyright_text": "Standard YouTube License",
  "description": "PyData DC 2016\n\nAlgorithms have become an integral part of our everyday lives. While algorithms can make our lives simpler and make decisions faster, there is a growing need for algorithms to be transparent and for the users of those algorithms to be accountable for the automated decisions made by them. This talk covers where algorithms are used, how they can go wrong, and how they can be investigated.\n\nAn algorithm is set of steps that perform calculations, process data, or automate tasks. Algorithms are everywhere we look (and even places we don\u2019t look) controlling what we see, do, and where we go. They\u2019re great for solving our problems and helping us make better and quicker decisions, or taking the decision-making out of our hands. Their guidance is perfect in their objective and unbiased calculation. Except they are not, actually. Like everything else, they are created by people, and people have biases that get encoded into the algorithms they create. Algorithms learn from data, which is also created by people, so the algorithms also learn biases from data. This can be a problem when algorithms encode these biases into their calculations and go on to perpetuate the bias.\n\nIn this talk you will hear why we should care about algorithmic accountability, and details on a case study on how computational journalism can be used to investigate algorithms and advocate the need for transparency and accountability.",
  "duration": 2103,
  "language": "eng",
  "recorded": "2016-10-09",
  "related_urls": [
    "http://pydata.org/dc2016/schedule/presentation/80/"
  ],
  "speakers": [
    "Jennifer Stark"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/0MGBM4ao8QE/maxresdefault.jpg",
  "title": "Exposing Algorithms",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=0MGBM4ao8QE"
    }
  ]
}
