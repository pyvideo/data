{"whiteboard": "needs editing", "video_mp4_download_only": false, "video_webm_download_only": false, "duration": null, "video_ogv_download_only": false, "category": "DjangoCon 2012", "speakers": ["David Gouldin"], "title": "Using Celery with Social Networks", "quality_notes": "", "video_flv_length": null, "recorded": "2012-09-05", "video_mp4_length": null, "description": "Twitter conditionally rate limits based on IP address rather than access token\neven when one is provided for some of its API calls. Facebook has at least 10\nunique error messages to indicate a bad or expired access token (that I've\nfound so far). LinkedIn's pagination has an occasional off-by-one bug\nresulting in an endless list of 1-user pages. Let's face it: interfacing with\nsocial networks is tricky. Celery helps, but to provide stable, reliable, and\nfast social features for your website, you'll need an arsenal of strategies\nand tools to get you the rest of the way there.\n\nBy the end of this talk, you'll understand how to set up tasks to quickly\nserve users with massive networks by employing intelligent distribution.\nYou'll be able to design robust processes to handle inconsistencies or\ninstabilities in 3rd party APIs. And you'll know how to have confidence that\nthe work you intend to do gets done, regardless of external rate limits,\npagination design, or API call dependency chains.\n\nThis talk is intended for people who have basic familiarity with celery and\nwould like to learn more about how to take advantage of it for large,\ndistributed task loads.\n\n## Outline\n\nI. Intro\n\nA. 3rd party interfaces are hard\n\n    \n      * Speed\n    \n        * Much slower than local data\n        * Users may still expect near-immediate results\n    \n      * Rate limits\n    \n        * Different rules for every service\n        * Need to handle reactive & proactive as some don't publish rates\n    \n      * Instability\n    \n        * Outages (yes, Facebook does go down)\n        * Random failures\n    \n\nB. Why Celery?\n\n    \n      * Asynchronous\n      * Distributed\n      * Fault tolerant\n    \n\nII. Task Organization\n\n    \n    A. Small, atomic tasks (1 API call per task)\n    B. Minimal message state\n    \n       * Primitive types only (no model instances!)\n       * Defer as much data access to the task itself as possible\n    \n    C. Create Task subclasses for common patterns\n    D. Whenever possible, make tasks idempotent\n    \n\nIII. Task Distribution\n\n    \n     A. Managing pagination\n    \n        * For a known set size\n    \n          * Where limit/offset is supported, launch all page tasks simlutaneously\n          * Otherwise, 1 page launches the next as soon as the next cursor is obtained\n    \n        * For an unknown set size\n    \n          * Set max simultaneous pages\n          * Task is terminal if blank, otherwise launches page w/ offset + max pages\n    \n        * Setting page size is an art, not a science\n    \n          * Minimize the number of api calls when possible\n          * Avoid long-running tasks by setting a timeout ceiling\n          * Avoid the temptation to pass API data to dependent tasks\n    \n     B. Tracking task dependencies (\"Done?\" is difficult for distributed systems)\n    \n        * Use an external backend to store a dependency tree\n        * Subclass ResultSet to evaluate the task state of the tree\n        * Requires ignore_result=False\n    \n\nIV. Rate Limiting\n\n    \n    A. Problems\n    \n       * Celery's rate limiting doesn't do what you think it does\n       * 3rd party rate limits depend on many factors\n    \n    B. Solution\n    \n       * For services with known rate limits:\n    \n         * Use an external backend to store rate limit counters\n         * Increment counters based on rate limit factors per api call\n    \n       * For services with unknown rate limits:\n    \n         * Use an external backend to store rate limit backoff counters\n         * Ramp up / ratchet down call rate by power law as api calls fail/succeed\n    \n\nV. Failover\n\nA. Problems\n\n    \n      * Celery's countdown doesn't do what you think it does\n      * 3rd parties can fail in lots of \"interesting\" ways\n    \n\nB. Solution\n\n    \n      * Implement native RabbitMQ alternative to countdown\n      * Create task base classes per social network to handle error conditions\n    \n\nVI. Multiple queues\n\n    \n    A. Better control over task priority management & resource distribution\n    B. Not all social accounts are created equal (handling whales & spikes)\n    C. When you can't stream updates, use a trickle queue\n    \n\nVII. Celerybeat considered harmful\n\n    \n     A. Periodic task persistence gets out of sync with code\n     B. Just 1 more process to manage\n     C. Cron: it's just. not. that. hard.\n    \n\nVIII. Debugging\n\n    \n      A. Don't use \"always eager\"\n      B. Logging, logging, logging\n      C. Unit tests are good, but integration tests save lives\n    \n\nIV. Gotchas\n\n    \n    A. Open socket prevents Celery soft timeout\n    B. Celery soft timeout doesn't retry the task\n    C. If result state is not known, Celery reports \"PENDING\"\n    \n\n", "video_mp4_url": null, "tags": ["celery", "django"], "copyright_text": "Creative Commons Attribution license (reuse allowed", "related_urls": [], "video_flv_download_only": false, "source_url": "http://www.youtube.com/watch?v=z751qhAzMb4", "video_webm_url": null, "video_ogv_length": null, "video_ogv_url": null, "language": "English", "video_webm_length": null, "summary": "Many web applications need to interface with social networks, and celery, a\nPython distributed task queue library, is a great tool for the job. However,\nachieving speed and stability can be difficult. This talk will cover task\norganization/distribution, rate limiting, failover, and other practices to aid\nin working with social networks at scale.\n\n", "thumbnail_url": "http://i.ytimg.com/vi/z751qhAzMb4/hqdefault.jpg", "video_flv_url": null}