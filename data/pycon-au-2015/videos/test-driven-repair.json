{"whiteboard": "needs editing", "video_mp4_download_only": false, "video_webm_download_only": false, "duration": null, "video_ogv_download_only": false, "category": "PyCon AU 2015", "speakers": ["Christopher Neugebauer"], "title": "Test-Driven Repair", "quality_notes": "", "video_flv_length": null, "recorded": "2015-08-04", "video_mp4_length": null, "description": "\u201cit is impossible BY DEFINITION to do Test-Driven Development after the code is written.\u201d \u2014 Tim Ottinger, author of \u2018Clean Code\u2019, on Twitter [1].\r\n\r\nAutomated testing is one of the most important tools in the modern programming toolbox: good tests help you find regressions early, and help you make sure your code is right before it ships. Test-driven development is a great way to make sure your software is up to specification before you start work. Even better, it makes sure your software\u2019s architecture is amenable to writing tests from day 1.\r\n\r\nSo what happens when you find yourself working on code where automated testing took a back seat to being shipped? Chances are you\u2019ll have a sea of bugs, strung together in a structure where writing simple unit tests just isn\u2019t going to happen.\r\n\r\nBroken code is a support burden, and if it\u2019s in production, you\u2019ve got no choice but to make things work. Luckily, automated testing isn\u2019t a lost cause here!\r\n\r\nIn this talk, we\u2019ll look at how to approach automated testing on late-stage, or even production code\u2026 or in any situation when you don\u2019t have the luxury of starting with a test-driven structure. We\u2019ll look at techniques that I\u2019ve used to analyse faults in existing code, and how to translate those into tests, and how to use that to fix bugs.\r\n\r\nIn particular, we\u2019ll look at:\r\n\r\n- Tooling and metrics to help you decide what code to test, and how to measure progress when you\u2019re writing tests\r\n- Approaches to constructing test cases for old code, including using data-driven approaches, and approaches based on requirements specifications\r\n- Granularity \u2014 making tests on old code granular enough is difficult, so we\u2019ll look at the trade-offs between unit and integration tests on old code, and ways to make integration-level tests granular enough to make results reliable\r\n\r\nWe\u2019ll see that testing old code is both achievable, and actually a worthwhile exercise. You\u2019ll find bugs. You\u2019ll increase quality. You\u2019ll make your code more maintainable! Do try it!\r\n\r\n[1] https://twitter.com/tottinge/status/544632253205475329\r\n\n\n", "video_mp4_url": null, "tags": [], "copyright_text": "creativeCommon", "related_urls": [], "video_flv_download_only": false, "source_url": "https://www.youtube.com/watch?v=1i5leCslA4g", "video_webm_url": null, "video_ogv_length": null, "video_ogv_url": null, "language": "English", "video_webm_length": null, "summary": "", "thumbnail_url": "https://i.ytimg.com/vi/1i5leCslA4g/hqdefault.jpg", "video_flv_url": null}