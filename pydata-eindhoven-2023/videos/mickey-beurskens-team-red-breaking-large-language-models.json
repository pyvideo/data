{
  "description": "The best way to learn how to secure a system is to know how it breaks! In this talk we will take on the role of the Red Team, try to break Large Language Models using prompt injection, and learn about the kind of havoc we can cause. Learn how to safeguard your LLM applications by understanding their weaknesses.",
  "duration": 1805,
  "language": "eng",
  "recorded": "2023-11-30",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://web.archive.org/web/20240930133013/http://pydata.org/eindhoven2023"
    }
  ],
  "speakers": [
    "Mickey Beurskens"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/F-UGqGsQvhc/maxresdefault.jpg",
  "title": "Team Red: Breaking Large Language Models",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=F-UGqGsQvhc"
    }
  ]
}
