{
  "description": "Large Language Models (LLM), like ChatGPT, have shown miraculous performances on various tasks. But there are still unsolved issues with these models: they can be confidently wrong and their knowledge becomes outdated. GPT also does not have any of the information that you have stored in your own data. In this talk, you'll learn how to use Haystack, an open source framework, to chain LLMs with other models and components to overcome these issues. We will build a practical application using these techniques. And you will walk away with a deeper understanding of how to use LLMs to build NLP products that work.",
  "duration": 1736,
  "language": "eng",
  "recorded": "2023-04-17",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://2023.pycon.de/"
    }
  ],
  "speakers": [
    "TODO"
  ],
  "tags": [
    "Education",
    "Julia",
    "NumFOCUS",
    "Opensource",
    "PyData",
    "Python",
    "Tutorial",
    "coding",
    "how to program",
    "learn",
    "learn to code",
    "python 3",
    "scientific programming",
    "software"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/-eRjgj1zww4/maxresdefault.jpg",
  "title": "Mathis Lucka: How to Feed Facts to Large Language Models and Reduce Hallucination.",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=-eRjgj1zww4"
    }
  ]
}
