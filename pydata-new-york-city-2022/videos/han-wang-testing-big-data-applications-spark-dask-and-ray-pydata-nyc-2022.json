{
  "description": "Distributed computing engines such as Spark, Dask, and Ray allow data practitioners to scale their data processing over a cluster of machines. The problem is that debugging and testing distributed computing code is notoriously hard. This is for both when iterating and for unit testing. Stacktraces can often become cryptic because distributed computing uses futures or async code under the hood.\n\nMore importantly, using these frameworks can lock in testing to depend on a cluster. Some libraries such as databricks-connect make it convenient to run code on a Spark cluster, but all testing code ends up running on the cluster as well. On a code level, distributed computing code often is a combination of logic and execution behavior. This makes it hard to unit test logic without testing execution code as well.\n\nIdeally, we want to test as much as possible locally. This speeds up iteration time and decreases computing expenses. Keeping code closer to native Python or Pandas also gives more intuitive tracebacks when errors arise. When we\u2019re production-ready, we can run the full test suite on the cluster.\n\nFugue is an abstraction layer for distributed computing that ports Python and Pandas code to Spark, Dask, and Ray. By using an abstraction layer, we can code in native Python or Pandas rather than using big data frameworks. Decoupling logic and execution dramatically reduces the overhead to run tests because tests can be run locally on Pandas or Python. Unit tests are easier to write because they focus on business logic on smaller data. When production-ready, Fugue allows users to toggle the execution engine and then the same code in a cluster.\n\nDistributed computing engines such as Spark, Dask, and Ray allow data practitioners to scale their data processing over a cluster of machines. The problem is that debugging and testing distributed computing code is notoriously hard. This is for both when iterating and for unit testing. Stacktraces can often become cryptic because distributed computing uses futures or async code under the hood.\n\nMore importantly, using these frameworks can lock in testing to depend on a cluster. Some libraries such as databricks-connect make it convenient to run code on a Spark cluster, but all testing code ends up running on the cluster as well. On a code level, distributed computing code often is a combination of logic and execution behavior. This makes it hard to unit test logic without testing execution code as well.\n\nIdeally, we want to test as much as possible locally. This speeds up iteration time and decreases computing expenses. Keeping code closer to native Python or Pandas also gives more intuitive tracebacks when errors arise. When we\u2019re production-ready, we can run the full test suite on the cluster.\n\nFugue is an abstraction layer for distributed computing that ports Python and Pandas code to Spark, Dask, and Ray. By using an abstraction layer, we can code in native Python or Pandas rather than using big data frameworks. Decoupling logic and execution dramatically reduces the overhead to run tests because tests can be run locally on Pandas or Python. Unit tests are easier to write because they focus on business logic on smaller data. When production-ready, Fugue allows users to toggle the execution engine and then the same code in a cluster.\n\nBio:\nHan Wang\nHan Wang is the lead of Lyft Machine Learning Platform, focusing on distributed computing and training. Before joining Lyft, he worked at Microsoft, Hudson River Trading, Amazon, and Quantlab. Han is the founder of the Fugue project, aiming at democratizing distributed computing and machine learning.\n\n===\n\nwww.pydata.org\n\nPyData is an educational program of NumFOCUS, a 501(c)3 non-profit organization in the United States. PyData provides a forum for the international community of users and developers of data analysis tools to share ideas and learn from each other. The global PyData network promotes discussion of best practices, new approaches, and emerging technologies for data management, processing, analytics, and visualization. PyData communities approach data science using many languages, including (but not limited to) Python, Julia, and R. \n\nPyData conferences aim to be accessible and community-driven, with novice to advanced level presentations. PyData tutorials and talks bring attendees the latest project features along with cutting-edge use cases.\n\n00:00 Welcome!\n00:10 Help us add time stamps or captions to this video! See the description for details.\n\nWant to help add timestamps to our YouTube videos to help with discoverability? Find out more here: https://github.com/numfocus/YouTubeVideoTimestamps",
  "duration": 2353,
  "language": "eng",
  "recorded": "2022-11-09",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pydata.org/nyc2022/"
    },
    {
      "label": "https://github.com/numfocus/YouTubeVideoTimestamps",
      "url": "https://github.com/numfocus/YouTubeVideoTimestamps"
    }
  ],
  "speakers": [
    "TODO"
  ],
  "tags": [
    "Education",
    "Julia",
    "NumFOCUS",
    "Opensource",
    "PyData",
    "Python",
    "Tutorial",
    "coding",
    "how to program",
    "learn",
    "learn to code",
    "python 3",
    "scientific programming",
    "software"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/yQHksEh1GCs/maxresdefault.jpg",
  "title": "Han Wang- Testing Big Data Applications (Spark, Dask, and Ray)| PyData NYC 2022",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=yQHksEh1GCs"
    }
  ]
}
