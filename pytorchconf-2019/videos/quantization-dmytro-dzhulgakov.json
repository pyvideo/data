{
  "description": "It\u2019s important to make efficient use of both server-side and on-device compute resources when developing ML applications. To support more efficient deployment on servers and edge devices, PyTorch 1.3 now supports 8-bit model quantization using the familiar eager mode Python API.",
  "duration": 593,
  "language": "eng",
  "recorded": "2019-10-16",
  "related_urls": [],
  "speakers": [
    "Dmytro Dzhulgakov"
  ],
  "tags": [
    "AI",
    "Artificial Intelligence",
    "Facebook",
    "ML",
    "Machine Learning",
    "Machine learning",
    "Machine learning applications",
    "PyTorch",
    "PyTorch 1.3",
    "PyTorch API",
    "PyTorch Quantization",
    "Quantization"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/IPQmGzYuxmc/maxresdefault.webp",
  "title": "Quantization",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=IPQmGzYuxmc"
    }
  ]
}
