{
  "description": "Lightning Talk: Exploring PiPPY, Tensor Parallel and Torchserve for Large Model Inference - Hamid Shojanazeri, Meta\n\nHere, we talk about large model inference with Torchserve, using PiPPy, Tensor Parallel, challenges of distributed inference and available solutions. Discuss the features that Torchserve provide today for serving LLMs in production today.",
  "duration": 753,
  "language": "eng",
  "recorded": "2023-10-16",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pytorch.org/event/pytorch-conference-2023/"
    }
  ],
  "speakers": [
    "TODO"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/QNQwbK2ZSFU/maxresdefault.jpg",
  "title": "Lightning Talk: Exploring PiPPY, Tensor Parallel and Torchserve for Large... - Hamid Shojanazeri",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=QNQwbK2ZSFU"
    }
  ]
}
