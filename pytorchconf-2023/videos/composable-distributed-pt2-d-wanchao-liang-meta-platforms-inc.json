{
  "description": "In this session, we will explore the technology advancements of PyTorch Distributed, and dive into the details of how multi-dimensional parallelism is made possible to train Large Language Models by composing different PyTorch native distributed training APIs.",
  "duration": 1149,
  "language": "eng",
  "recorded": "2023-10-16",
  "related_urls": [
    {
      "label": "Conference Website",
      "url": "https://pytorch.org/event/pytorch-conference-2023/"
    }
  ],
  "speakers": [
    "Wanchao Liang"
  ],
  "tags": [],
  "thumbnail_url": "https://i.ytimg.com/vi/LcDjYLJblEY/maxresdefault.jpg",
  "title": "Composable Distributed PT2(D)",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=LcDjYLJblEY"
    }
  ]
}
