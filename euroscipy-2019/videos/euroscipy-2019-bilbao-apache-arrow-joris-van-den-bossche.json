{
  "description": "This talk discusses Apache Arrow project and how it already interacts\nwith the Python ecosystem.\n\nThe Apache Arrow project specifies a standardized language-independent\ncolumnar memory format for flat and nested data, organized for efficient\nanalytic operations on modern hardware. On top of that standard, it\nprovides computational libraries and zero-copy streaming messaging and\ninterprocess communication protocols, and as such, it provides a\ncross-language development platform for in-memory data. It has support\nfor many languages, including C, C++, Java, JavaScript, MATLAB, Python,\nR, Rust, ..\n\nThe Apache Arrow project, although still in active development, has\nalready several applications in the Python ecosystem. For example, it\nprovides the IO functionality for pandas to read the Parquet format (a\ncolumnar, binary file format used a lot in the Hadoop ecosystem). Thanks\nto the standard memory format, it can help improve interoperability\nbetween systems, and this is already seen in practice for the Spark /\nPython interface, by increasing the performance of PySpark. Further, it\nhas the potential to provide a more performant string data type and\nnested data types (like dicts or lists) for Pandas dataframes, which is\nalready being experimented with in the fletcher package (using the\npandas ExtensionArray interface).\n\nApache Arrow, defining a columnar, in-memory data format standard and\ncommunication protocols, provides a cross-language development platform\nwith already several applications in the PyData ecosystem.\n",
  "duration": 1789,
  "language": "eng",
  "recorded": "2019-09-04",
  "speakers": [
    "Joris Van den Bossche"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi/4BEQyCu45lE/hqdefault.jpg",
  "title": "Apache Arrow: a cross-language development platform for in-memory data",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=4BEQyCu45lE"
    }
  ]
}
